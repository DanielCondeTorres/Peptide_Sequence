
from dataclasses import dataclass
from typing import Optional, Dict, List
import numpy as np
from Peptide_sequence_lib.AminoAcid_Properties import AminoAcid_Properties
import numpy as np
from typing import Dict, List, Optional, Tuple
from scipy.optimize import minimize, differential_evolution
import logging
import time

class QuantumOptimizer:
    """Quantum optimizer using VQE (Qiskit 2.x, manual classical optimizer) - Improved Version"""
    
    def __init__(self, use_simulator: bool = True, seed: int = 42):
        self.use_simulator = use_simulator
        self.seed = seed
        np.random.seed(seed)
        self.logger = logging.getLogger(__name__)
        
    def calculate_energy(self, sequence: str, constraints: Dict) -> float:
        """
        Calcula la energ칤a de una secuencia de p칠ptido usando las mismas reglas que el modo cu치ntico.
        Versi칩n mejorada con mejor balance de t칠rminos.
        """
        aa_props = AminoAcid_Properties()
        energy = 0.0
        
        # Binding affinity term (hidrofobicidad) - Mejorado
        hydrophobic_reward = constraints.get('hydrophobic_reward', 1.0)
        hydrophobic_energy = 0.0
        for aa in sequence:
            hydrophobic_energy -= hydrophobic_reward * aa_props.hydrophobicity.get(aa, 0)
        energy += hydrophobic_energy
        
        # Stability term (penaliza combinaciones inestables) - Mejorado
        stability_penalty = constraints.get('stability_penalty', 1.0)
        stability_energy = 0.0
        for i in range(len(sequence) - 1):
            aa1, aa2 = sequence[i], sequence[i+1]
            
            # Penalizaci칩n por repetici칩n
            if aa1 == aa2:
                stability_energy += stability_penalty
            
            # Penalizaci칩n adicional por patrones desfavorables
            unfavorable_pairs = constraints.get('unfavorable_pairs', {})
            pair = aa1 + aa2
            if pair in unfavorable_pairs:
                stability_energy += unfavorable_pairs[pair] * stability_penalty
        
        energy += stability_energy
        
        # Diversity term - Mejorado
        diversity_reward = constraints.get('diversity_reward', 0.5)
        unique_aa = len(set(sequence))
        max_diversity = min(len(sequence), len(aa_props.amino_acids))
        diversity_ratio = unique_aa / max_diversity
        energy -= diversity_reward * diversity_ratio * len(sequence)
        
        # T칠rmino de longitud 칩ptima
        target_length = constraints.get('target_length', len(sequence))
        length_penalty = constraints.get('length_penalty', 0.1)
        energy += length_penalty * abs(len(sequence) - target_length)
        
        return energy

    def params_to_sequence(self, params: np.ndarray, peptide_length: int, aa_list: List[str]) -> str:
        """
        Mapea los par치metros del ansatz a una secuencia usando softmax por posici칩n.
        Versi칩n mejorada con mejor normalizaci칩n.
        """
        params = np.array(params)
        n_aa = len(aa_list)
        
        # Asegurar que tenemos suficientes par치metros
        required_params = peptide_length * n_aa
        if len(params) < required_params:
            params = np.pad(params, (0, required_params - len(params)), mode='constant')
        
        params = params[:required_params].reshape((peptide_length, n_aa))
        
        # Softmax mejorado con temperatura
        temperature = 1.0
        exp_params = np.exp((params - np.max(params, axis=1, keepdims=True)) / temperature)
        probs = exp_params / np.sum(exp_params, axis=1, keepdims=True)
        
        # Selecci칩n determin칤stica (argmax) o estoc치stica
        use_stochastic = False  # Cambiar a True para selecci칩n estoc치stica
        if use_stochastic:
            indices = [np.random.choice(n_aa, p=prob_dist) for prob_dist in probs]
        else:
            indices = np.argmax(probs, axis=1)
        
        sequence = ''.join([aa_list[i] for i in indices])
        return sequence

    def optimize_peptide(self, 
                        peptide_length: int, 
                        constraints: Dict, 
                        num_reads: int = 10000, 
                        use_classical: bool = False, 
                        maxiter_cobyla: int = 100, 
                        optimizer: str = 'COBYLA', 
                        use_qaoa: bool = True) -> List[Dict]:
        """
        Optimiza el p칠ptido usando m칠todo cu치ntico (VQE manual) o cl치sico (random search).
        Versi칩n mejorada con mejor manejo de errores y logging.
        """
        start_time = time.time()
        print('METODOS: ',optimizer,use_qaoa)
        # Validaci칩n de par치metros
        if peptide_length <= 0:
            raise ValueError("peptide_length debe ser positivo")
        
        if not isinstance(constraints, dict):
            raise ValueError("constraints debe ser un diccionario")
        
        n_aminoacids = len(AminoAcid_Properties().amino_acids)
        aa_list = AminoAcid_Properties().amino_acids
        
        if use_classical:
            return self._optimize_classical(peptide_length, constraints, num_reads, aa_list)
        
        if use_qaoa:
            return self._optimize_qaoa_improved(peptide_length, constraints, maxiter_cobyla, aa_list)
        
        # VQE por defecto
        return self._optimize_vqe(peptide_length, constraints, maxiter_cobyla, optimizer, aa_list)

    def _optimize_classical(self, peptide_length: int, constraints: Dict, num_reads: int, aa_list: List[str]) -> List[Dict]:
        """Optimizaci칩n cl치sica mejorada con mejor sampling"""
        self.logger.info(f"Modo: Optimizaci칩n cl치sica (random search reproducible, {num_reads} muestras)")
        
        solutions = []
        
        # Estrategia 1: B칰squeda completamente aleatoria (70%)
        random_samples = int(0.7 * num_reads)
        for _ in range(random_samples):
            sequence = ''.join(np.random.choice(aa_list, peptide_length))
            energy = self.calculate_energy(sequence, constraints)
            solutions.append({
                'sequence': sequence,
                'energy': energy,
                'sample': {},
                'method': 'random'
            })
        
        # Estrategia 2: B칰squeda sesgada hacia amino치cidos hidrof칩bicos (30%)
        if 'hydrophobic_reward' in constraints and constraints['hydrophobic_reward'] > 0:
            biased_samples = num_reads - random_samples
            # Crear pesos basados en hidrofobicidad
            aa_props = AminoAcid_Properties()
            weights = np.array([max(0, aa_props.hydrophobicity.get(aa, 0)) for aa in aa_list])
            weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(aa_list)) / len(aa_list)
            
            for _ in range(biased_samples):
                sequence = ''.join(np.random.choice(aa_list, peptide_length, p=weights))
                energy = self.calculate_energy(sequence, constraints)
                solutions.append({
                    'sequence': sequence,
                    'energy': energy,
                    'sample': {},
                    'method': 'biased_hydrophobic'
                })
        
        solutions.sort(key=lambda x: x['energy'])
        return solutions

    def _optimize_qaoa_improved(self, peptide_length: int, constraints: Dict, maxiter: int, aa_list: List[str]) -> List[Dict]:
        """
        Modo QAOA mejorado con funci칩n de coste espec칤fica y optimizaci칩n differential evolution.
        Si el n칰mero de qubits es mayor a 30, se usa un QAOA temporal simplificado.
        """
        try:
            from qiskit_optimization import QuadraticProgram
            from qiskit.circuit.library import QAOAAnsatz
            from qiskit.primitives import Estimator
            from qiskit_aer import Aer
            from scipy.optimize import differential_evolution
        except ImportError as e:
            self.logger.error(f"Librer칤as de Qiskit no disponibles: {e}")
            return self._optimize_classical(peptide_length, constraints, 1000, aa_list)

        n_blocks = peptide_length
        n_aa = len(aa_list)
        n_qubits = n_blocks * n_aa

        if n_qubits > 30:
            self.logger.info(f"Qubits = {n_qubits} > 30, ejecutando QAOA temporal (tmp).")
            return self._optimize_qaoa_tmp(peptide_length, constraints, maxiter, aa_list)

        self.logger.info("Modo: Optimizaci칩n cu치ntica (QAOA con funci칩n de coste y differential evolution)")
        print('QAOA USED')

        # Construir QUBO mejorado
        linear, quadratic = self._build_improved_qubo(n_blocks, n_aa, aa_list, constraints)

        # Crear problema cuadr치tico
        qp = QuadraticProgram()
        for i in range(n_qubits):
            qp.binary_var(name=f'x_{i}')
        qp.minimize(linear=linear, quadratic=quadratic)

        # Convertir a QUBO
        from qiskit_optimization.converters import QuadraticProgramToQubo
        qp2qubo = QuadraticProgramToQubo()
        qubo = qp2qubo.convert(qp)

        # Crear circuito QAOA
        p = 1  # profundidad del ansatz
        qaoa_ansatz = QAOAAnsatz(qubo, reps=p)

        # Configurar Estimator backend
        backend = Aer.get_backend('aer_simulator_statevector')
        estimator = Estimator(backend=backend)

        def cost_function(params):
            # params es un array de 치ngulos del ansatz
            qc = qaoa_ansatz.assign_parameters(params)
            result = estimator.run(qc).result()
            energy = result.values[0]
            return energy

        # Optimizaci칩n con differential evolution
        bounds = [(0, 2 * 3.141592653589793)] * qaoa_ansatz.num_parameters

        result = differential_evolution(cost_function, bounds, maxiter=maxiter)

        best_params = result.x
        best_energy = result.fun

        # Interpretar resultado: decodificar la mejor configuraci칩n (binaria)
        qc_best = qaoa_ansatz.assign_parameters(best_params)
        counts = estimator.run(qc_best).result().quasi_dists[0]  # quasi-distribution
        # Buscar la configuraci칩n con mayor probabilidad
        best_bitstring = max(counts, key=counts.get)

        # Convertir bitstring a secuencia de amino치cidos
        sequence = self._bitstring_to_sequence(best_bitstring, peptide_length, aa_list)

        return [{
            'sequence': sequence,
            'energy': best_energy,
            'sample': {'bitstring': best_bitstring},
            'method': 'qaoa_improved',
            'optimizer': 'differential_evolution',
            'result': result
        }]



    def _optimize_qaoa_tmp(self, peptide_length: int, constraints: Dict, maxiter: int, aa_list: List[str]) -> List[Dict]:
        """
        Implementaci칩n simplificada de QAOA para fallback cuando hay m치s de 30 qubits.
        Aqu칤 puedes usar un m칠todo cl치sico, un ansatz m치s simple, o simplemente devolver una soluci칩n b치sica.
        """
        self.logger.info("Ejecutando QAOA temporal simplificado para muchos qubits (>30).")

        # Por ejemplo, llamar a la optimizaci칩n cl치sica como fallback:
        return self._optimize_classical(peptide_length, constraints, maxiter, aa_list)


    def _build_improved_qubo(self, n_blocks: int, n_aa: int, aa_list: List[str], constraints: Dict) -> Tuple[Dict, Dict]:
        """
        Construye un QUBO mejorado con mejor representaci칩n del problema.
        """
        linear = {}
        quadratic = {}
        
        # Penalizaci칩n one-hot m치s fuerte
        penalty = constraints.get('one_hot_penalty', 10.0)
        
        # Restricciones one-hot por posici칩n
        for p in range(n_blocks):
            # T칠rmino lineal: -penalty * sum(x_{p,a})
            for a in range(n_aa):
                idx = p * n_aa + a
                linear[idx] = linear.get(idx, 0) - penalty
            
            # T칠rmino cuadr치tico: penalty * sum_{a<b} x_{p,a} * x_{p,b}
            for a in range(n_aa):
                for b in range(a + 1, n_aa):
                    idx1 = p * n_aa + a
                    idx2 = p * n_aa + b
                    quadratic[(idx1, idx2)] = quadratic.get((idx1, idx2), 0) + penalty
        
        # T칠rminos de energ칤a mejorados
        aa_props = AminoAcid_Properties()
        
        # T칠rmino de hidrofobicidad
        hydrophobic_reward = constraints.get('hydrophobic_reward', 1.0)
        for p in range(n_blocks):
            for a in range(n_aa):
                idx = p * n_aa + a
                hydrophobic_contrib = hydrophobic_reward * aa_props.hydrophobicity.get(aa_list[a], 0)
                linear[idx] = linear.get(idx, 0) - hydrophobic_contrib
        
        # T칠rmino de estabilidad (interacciones entre posiciones adyacentes)
        stability_penalty = constraints.get('stability_penalty', 1.0)
        for p in range(n_blocks - 1):
            for a in range(n_aa):
                for b in range(n_aa):
                    idx1 = p * n_aa + a
                    idx2 = (p + 1) * n_aa + b
                    
                    # Penalizar repeticiones
                    if a == b:
                        quadratic[(idx1, idx2)] = quadratic.get((idx1, idx2), 0) + stability_penalty
        
        return linear, quadratic

    def _bitstring_to_sequence(self, bitstring: str, n_blocks: int, n_aa: int, aa_list: List[str]) -> str:
        """
        Convierte un bitstring a secuencia de amino치cidos.
        Maneja casos donde no hay exactamente un bit activo por bloque.
        """
        sequence = []
        bitstring_reversed = bitstring[::-1]  # Qiskit usa little-endian
        
        for block in range(n_blocks):
            block_bits = bitstring_reversed[block * n_aa:(block + 1) * n_aa]
            
            # Buscar el primer bit activo
            active_indices = [i for i, bit in enumerate(block_bits) if bit == '1']
            
            if len(active_indices) == 1:
                # Caso ideal: exactamente un bit activo
                sequence.append(aa_list[active_indices[0]])
            elif len(active_indices) > 1:
                # M칰ltiples bits activos: tomar el primero
                sequence.append(aa_list[active_indices[0]])
            else:
                # Ning칰n bit activo: usar amino치cido por defecto
                sequence.append(aa_list[0])  # 'A' por defecto
        
        return ''.join(sequence)
def _optimize_vqe(self, peptide_length: int, constraints: Dict, maxiter: int, optimizer: str, aa_list: List[str]) -> List[Dict]:
    """
    Optimizaci칩n VQE cu치ntica real usando Qiskit, RealAmplitudes y Estimator.
    """
    self.logger.info("Modo: Optimizaci칩n VQE cu치ntico real")
    print('VQE QUANTUM USED')

    try:
        from qiskit_optimization import QuadraticProgram
        from qiskit_optimization.converters import QuadraticProgramToQubo
        from qiskit.circuit.library import RealAmplitudes
        from qiskit.primitives import Estimator
        from qiskit_aer import Aer
        from qiskit import QuantumCircuit
    except ImportError as e:
        self.logger.error(f"Qiskit requerido para VQE cu치ntico: {e}")
        return self._optimize_classical(peptide_length, constraints, 1000, aa_list)

    n_blocks = peptide_length
    n_aa = len(aa_list)
    n_qubits = n_blocks * n_aa

    # 游뛂 Verificaci칩n de qubits
    if n_qubits > 30:
        self.logger.error(f"Demasiados qubits para VQE cu치ntico: {n_qubits}. M치ximo recomendado: 30")
        return self._optimize_classical(peptide_length, constraints, 1000, aa_list)

    # Crear QUBO
    linear, quadratic = self._build_improved_qubo(n_blocks, n_aa, aa_list, constraints)

    qp = QuadraticProgram()
    for i in range(n_qubits):
        qp.binary_var(name=f'x_{i}')
    qp.minimize(linear=linear, quadratic=quadratic)

    # Convertir a Ising Hamiltonian
    try:
        qubo = QuadraticProgramToQubo().convert(qp)
        cost_operator, offset = qubo.to_ising()
    except Exception as e:
        self.logger.error(f"Fallo al convertir a operador Ising: {e}")
        return self._optimize_classical(peptide_length, constraints, 1000, aa_list)

    # Crear ansatz
    ansatz = RealAmplitudes(num_qubits=n_qubits, reps=2, entanglement='linear')

    estimator = Estimator()

    def vqe_cost_function(params):
        try:
            result = estimator.run([ansatz], [cost_operator], [params]).result()
            return result.values[0] + offset
        except Exception as e:
            self.logger.warning(f"Error al evaluar VQE: {e}")
            return float('inf')

    # Optimizaci칩n cl치sica
    bounds = [(-2*np.pi, 2*np.pi)] * ansatz.num_parameters
    best_result = differential_evolution(
        vqe_cost_function,
        bounds,
        maxiter=maxiter,
        seed=self.seed,
        atol=1e-6,
        tol=1e-6,
        polish=True,
        workers=1
    )

    if not best_result.success:
        self.logger.warning(f"VQE no convergi칩: {best_result.message}")
        return self._optimize_classical(peptide_length, constraints, 1000, aa_list)

    # Construir circuito final
    qc = QuantumCircuit(n_qubits)
    qc.append(ansatz.assign_parameters(best_result.x), range(n_qubits))
    qc.measure_all()

    backend = Aer.get_backend('aer_simulator')
    job = backend.run(qc, shots=2048)
    counts = job.result().get_counts()

    # Analizar bitstrings
    best_solutions = []
    total_shots = sum(counts.values())

    for bitstring, count in counts.items():
        if count / total_shots > 0.01:
            sequence = self._bitstring_to_sequence(bitstring, n_blocks, n_aa, aa_list)
            actual_energy = self.calculate_energy(sequence, constraints)
            best_solutions.append({
                'sequence': sequence,
                'energy': actual_energy,
                'probability': count / total_shots,
                'bitstring': bitstring
            })

    best_solutions.sort(key=lambda x: x['energy'])

    if not best_solutions:
        self.logger.error("No se obtuvieron soluciones v치lidas del circuito VQE")
        return self._optimize_classical(peptide_length, constraints, 1000, aa_list)

    return [{
        'sequence': best_solutions[0]['sequence'],
        'energy': best_solutions[0]['energy'],
        'sample': counts,
        'method': 'vqe_quantum',
        'vqe_result': best_result,
        'optimizer': 'differential_evolution',
        'probability': best_solutions[0]['probability'],
        'bitstring': best_solutions[0]['bitstring'],
        'num_evaluations': best_result.nfev,
        'all_solutions': best_solutions[:5]
    }]


    def _smart_initialization(self, peptide_length: int, constraints: Dict, aa_list: List[str]) -> np.ndarray:
        """
        Inicializaci칩n inteligente de par치metros basada en las restricciones.
        """
        n_aa = len(aa_list)
        params = np.zeros(peptide_length * n_aa)
        
        # Sesgar hacia amino치cidos hidrof칩bicos si es beneficial
        if constraints.get('hydrophobic_reward', 0) > 0:
            aa_props = AminoAcid_Properties()
            for pos in range(peptide_length):
                for aa_idx, aa in enumerate(aa_list):
                    param_idx = pos * n_aa + aa_idx
                    hydrophobic_value = aa_props.hydrophobicity.get(aa, 0)
                    params[param_idx] = hydrophobic_value * 0.5  # Sesgo suave
        
        return params